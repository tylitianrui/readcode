# 数据采集scrape模块
无论是静态文件 还是通过服务发现，我们都已经解决**监控谁**的问题.那么下面就要拉取监控指标了。在`Prometheus`中由`Scrape.Manager`(定义文件`scrape/manager.go`) 管理监控对象。

##  Scrape.Manager 定义
文件: `scrape/manager.go` 
```
// Manager maintains a set of scrape pools and manages start/stop cycles
// when receiving new target groups from the discovery manager.
type Manager struct {
	opts      *Options
	logger    log.Logger
	append    storage.Appendable
	graceShut chan struct{}

	offsetSeed    uint64     // Global offsetSeed seed is used to spread scrape workload across HA setup.
	mtxScrape     sync.Mutex // Guards the fields below.
	scrapeConfigs map[string]*config.ScrapeConfig   // prometheus.yml配置文件中scrape_configs模块信息: 拉取的target配置的初始值信息,key为job_name
	scrapePools   map[string]*scrapePool
	targetSets    map[string][]*targetgroup.Group  // target更新要拉取的具体target,key为job_name
	buffers       *pool.Pool

	triggerReload chan struct{}  // 传递reload信号的channel，通过监听此channel进行reload操作

	metrics *scrapeMetrics
}
```


## 监控对象

根据配置文件`prometheus.yml`中关于监控对象的配置，如下： 
**demo:4.0.1**  
```
scrape_configs:
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
  - job_name: "job-0"
    metrics_path: '/metrics'
    scheme : 'http'
    static_configs:
      - targets: ["127.0.0.1:8520","192.168.0.103:8520"]
```
可以看出：
- 所有的监控对象是按照监控对象进行分组的，每个组都有一个`job_name`,例如：`job_name: "prometheus"`,`job_name: "job-0"`
- 每个监控对象的`targets`有多个具体的`endpoint`，例如 `job-0`的 `targets:["127.0.0.1:8520","192.168.0.103:8520"]`


`prometheus`中`Scrape.Manager.targetSets` 就是管理这些**监控对象**的数据结构,类型：`map[string][]*targetgroup.Group`
- 这个`map`的`key`就是配置中的`job_name`
- 这个`map`的`value`类型：`[]*targetgroup.Group`。 `targetgroup.Group` 定义如下:  
```
type Group struct {
	Targets []model.LabelSet  // model.LabelSet 本质是map[string]string
	Labels model.LabelSet     // model.LabelSet 本质是map[string]string

	// Source is an identifier that describes a group of targets.
	Source string
}
```

`demo:4.0.1`对应`Scrape.Manager.targetSets`的数据结构： 

```
{
    "prometheus": [
        {
            "Targets": [
                {
                    "__address__": "localhost:9090"
                }
            ],
            "Labels": null,
            "Source": "0"
        }
    ],
    "job-0": [
        {
            "Targets": [
                {
                    "__address__": "127.0.0.1:8520"
                },
                {
                    "__address__": "192.168.0.103:8520"
                }
            ],
            "Labels": null,
            "Source": "0"
        }
    ]
}

```


## `Scrape Manager`执行过程

`Scrape Manager`(*注：`cmd/prometheus/main.go`*)入口代码如下：  
```
{
		// Scrape manager.
		g.Add(
			func() error {
				// When the scrape manager receives a new targets list
				// it needs to read a valid config for each job.
				// It depends on the config being in sync with the discovery manager so
				// we wait until the config is fully loaded.
				<-reloadReady.C

				err := scrapeManager.Run(discoveryManagerScrape.SyncCh())
				level.Info(logger).Log("msg", "Scrape manager stopped")
				return err
			},
			func(err error) {
				// Scrape manager needs to be stopped before closing the local TSDB
				// so that it doesn't try to write samples to a closed storage.
				// We should also wait for rule manager to be fully stopped to ensure
				// we don't trigger any false positive alerts for rules using absent().
				level.Info(logger).Log("msg", "Stopping scrape manager...")
				scrapeManager.Stop()
			},
		)
	}
```

说明： 
- `err := scrapeManager.Run(discoveryManagerScrape.SyncCh())`  传入的参数是`chan`，`send`端是`discovery`组件，将最新的`targets`传递给`scrape`组件，`scrape`组件更新拉取的目标地址等信息
  
<br/>  

监听target变化：  
```
// Run receives and saves target set updates and triggers the scraping loops reloading.
// Reloading happens in the background so that it doesn't block receiving targets updates.

func (m *Manager) Run(tsets <-chan map[string][]*targetgroup.Group) error {
	go m.reloader()
	// 循环
	for {
		select {
		case ts := <-tsets:   // 在chan tsets 获取到当前targets, chan tsets的send端一般是服务发现组件
			m.updateTsets(ts) // 更新targets,将 m.targetSets 设置为ts

			select {
			case m.triggerReload <- struct{}{}:  // 发生reload信号
			default:
			}

		case <-m.graceShut:
			return nil
		}
	}
}

func (m *Manager) updateTsets(tsets map[string][]*targetgroup.Group) {
	m.mtxScrape.Lock()
	m.targetSets = tsets
	m.mtxScrape.Unlock()
}

```

监听reload信号，加载target

```

func (m *Manager) reloader() {
	reloadIntervalDuration := m.opts.DiscoveryReloadInterval
	if reloadIntervalDuration < model.Duration(5*time.Second) {
		reloadIntervalDuration = model.Duration(5 * time.Second)
	}

	ticker := time.NewTicker(time.Duration(reloadIntervalDuration))

	defer ticker.Stop()

	for {
		select {
		case <-m.graceShut:
			return
		case <-ticker.C:
			select {
			case <-m.triggerReload: // 监听到reload信号，执行reload操作
				m.reload()          // 实际上加载targets的操作
			case <-m.graceShut:
				return
			}
		}
	}
}
``` 
  
说明：
- 通过 `chan tsets` 接受到获取到当前监控的`targets`,暂存在 `scrapeManager`对象的`targetSets`字段，以待更新，并且向 `scrapeManager`对象的`triggerReload`发送信号
- `reloader`方法定期(默认5秒)去尝试获取`scrapeManager`对象的`triggerReload`信号。接收到reload信号，则执行`m.reload()` 加载

<br/>  


Manager.reload-热加载的实际执行者
  
```

func (m *Manager) reload() {
	m.mtxScrape.Lock()
	var wg sync.WaitGroup
	// m.targetSets 暂存的是当前最新的抓取目标，是在 Manager.Run--> Manager.updateTsets(ts) 中进行设置的  
    // 遍历m.targetSets为每个job创建 scrapePool
	for setName, groups := range m.targetSets {
		if _, ok := m.scrapePools[setName]; !ok {
			scrapeConfig, ok := m.scrapeConfigs[setName]
			if !ok {
				level.Error(m.logger).Log("msg", "error reloading target set", "err", "invalid config id:"+setName)
				continue
			}
			m.metrics.targetScrapePools.Inc()
			sp, err := newScrapePool(scrapeConfig, m.append, m.offsetSeed, log.With(m.logger, "scrape_pool", setName), m.buffers, m.opts, m.metrics)
			if err != nil {
				m.metrics.targetScrapePoolsFailed.Inc()
				level.Error(m.logger).Log("msg", "error creating new scrape pool", "err", err, "scrape_pool", setName)
				continue
			}
			m.scrapePools[setName] = sp
		}

		wg.Add(1)
		// Run the sync in parallel as these take a while and at high load can't catch up.
		go func(sp *scrapePool, groups []*targetgroup.Group) {
			sp.Sync(groups)
			wg.Done()
		}(m.scrapePools[setName], groups)

	}
	m.mtxScrape.Unlock()
	wg.Wait()
}
```