# 数据采集scrape模块(todo)
无论是静态文件 还是通过服务发现，我们都已经解决**监控谁**的问题.那么下面就要拉取监控指标了。数据采集scrape模块主要有两方面的功能:
- **管理、更新待拉取的目标** : 通过服务发现，`Prometheus`总是会拿到当前最新的监控对象的信息(*例如：拉取`mertics`的地址等*)。`scrape.Manager`对象负责这些需要进行scrape的target
- **拉取mertics** : 发起`http(s)`请求,拉取监控指标




## 管理、更新待拉取的目标

在`Prometheus`中由`Scrape.Manager`(定义文件`scrape/manager.go`) 管理监控对象。

### `Scrape.Manager` 

文件: `scrape/manager.go` 
```go
// Manager maintains a set of scrape pools and manages start/stop cycles
// when receiving new target groups from the discovery manager.
// scrape.Manager维护一组scrapePool,scrapePool负责拉取监控指标等工作
// 当通过 discover manager 获取到当前最新的抓取目标的时，scrape.Manager热更新最新的监控目标 并管理scrapePool循环的的启动、关闭  

type Manager struct {
	opts      *Options
	logger    log.Logger
	append    storage.Appendable                      // 存储
	graceShut chan struct{}                           // 关闭信号

	offsetSeed    uint64     
	mtxScrape     sync.Mutex 
	scrapeConfigs map[string]*config.ScrapeConfig    // prometheus.yml配置文件中scrape_configs模块信息: 拉取的target配置的初始值信息,key为job_name
	scrapePools   map[string]*scrapePool             // 存储了一组拉取指标的实际执行者
	targetSets    map[string][]*targetgroup.Group    // target更新要拉取的具体target,key为job_name
	buffers       *pool.Pool

	triggerReload chan struct{}                      // 传递reload信号的channel，通过监听此channel进行reload操作

	metrics *scrapeMetrics                           // 对scrape模块监控指标
}
```  

**主要字段**：
| 字段名   | 类型    |说明 | 
| :-----| :---- | :---- |
| `scrapeConfigs`  |`map[string]*config.ScrapeConfig` | `prometheus.yml`配置文件中`scrape_configs`部分的信息。<br/>  `map`的`key`是`prometheus.yml`配置文件中的`job_name`<br/>  `map`的`value`是对应的配置内容  |
| `scrapePools`   |`map[string]*scrapePool` | 存储了一组拉取指标的实际执行者 <br/>  `map`的`key`是`job_name`<br/>  `map`的`value`类型是`scrapePool` ,是拉取对应`job_name`指标的实际工作者。 |
| `targetSets`   |`map[string][]*targetgroup.Group` | 服务发现模块会将当前最新的监控对象封装成`map[string][]*targetgroup.Group`，通过`channel`(注：`channel`的类型`chan map[string][]*targetgroup.Group`)发送给`scrape.Manager`。<br/>   `scrape.Manager`会把接收到的信息暂存在`targetSets`字段。<br/>  `map`的`key`是`job_name`,<br/>  `map`的`value`就是对应的监控对象信息 |
| `triggerReload`  |`chan struct{}`  | 用于传递热更新信号，<br/>  `scrape.Manager`将接收到的信息暂存在`targetSets`字段后，会向`triggerReload`发送更新信号。`scrape.Manager`的`reloader`方法接收到更新信号后，调用更新操作。 |

<br/>  
<br/>  

### `targetgroup.Group`
在`prometheus`中, 所有的监控对象都是分组的,`targetgroup.Group`类型就是拉取监控对象信息的封装(例如：拉取metrics的地址等),
```go
type Group struct {
	Targets []model.LabelSet  // model.LabelSet 本质是map[string]string
	Labels model.LabelSet     // model.LabelSet 本质是map[string]string
	Source string
}
```  

关键字段：
- `Targets` 类型`[]model.LabelSet` ,`model.LabelSet`是`map[string]string`类型的别名。`Targets`用来存储拉取metrics的地址等  

<br/>  

**示例4.0.1 以静态文件配置为例进行说明**  

`prometheus.yml`中`scrape_configs`部分的配置，如下：  

```yaml
scrape_configs:
  - job_name: "prometheus"
    static_configs:
      - targets: ["localhost:9090"]
  - job_name: "job-0"
    metrics_path: '/metrics'
    scheme : 'http'
    static_configs:
      - targets: ["127.0.0.1:8520","192.168.0.103:8520"]
```  
<br/>  

`job-0`对应的`targetgroup.Group`实例：  

```json
	{
	  "Targets": [
	      {
	          "__address__": "127.0.0.1:8520"
	      },
	      {
	          "__address__": "192.168.0.103:8520"
	      }
	  ],
	  "Labels": null,
	  "Source": "0"
	}

```
<br/>   

`scrape_configs`配置对应`Scrape.Manager.targetSets`的数据结构： 

```json
{
    "prometheus": [
        {
            "Targets": [
                {
                    "__address__": "localhost:9090"
                }
            ],
            "Labels": null,
            "Source": "0"
        }
    ],
    "job-0": [
        {
            "Targets": [
                {
                    "__address__": "127.0.0.1:8520"
                },
                {
                    "__address__": "192.168.0.103:8520"
                }
            ],
            "Labels": null,
            "Source": "0"
        }
    ]
}

```


### 更新targets  
  

`Scrape Manager`(*注：`cmd/prometheus/main.go`*)入口代码如下：  
```go
	{
		// Scrape manager.
		g.Add(
			func() error {
				// When the scrape manager receives a new targets list
				// it needs to read a valid config for each job.
				// It depends on the config being in sync with the discovery manager so
				// we wait until the config is fully loaded.
				<-reloadReady.C

				err := scrapeManager.Run(discoveryManagerScrape.SyncCh())
				level.Info(logger).Log("msg", "Scrape manager stopped")
				return err
			},
			func(err error) {
				// Scrape manager needs to be stopped before closing the local TSDB
				// so that it doesn't try to write samples to a closed storage.
				// We should also wait for rule manager to be fully stopped to ensure
				// we don't trigger any false positive alerts for rules using absent().
				level.Info(logger).Log("msg", "Stopping scrape manager...")
				scrapeManager.Stop()
			},
		)
	}
```

**说明**：
启动`scrapeManager`: `err := scrapeManager.Run(discoveryManagerScrape.SyncCh())` 
- `discoveryManagerScrape.SyncCh()` 返回`chan map[string][]*targetgroup.Group`。服务发现模块(`discoveryManagerScrape`)会通过此`channel` 向`scrape`模块(`scrapeManager`)发送当前最新的拉取对象的信息(`targetgroup.Group`)
- `scrapeManager.Run(chan map[string][]*targetgroup.Group)`，启动`scrapeManager`，准备接收到当前最新的拉取对象的信息(`targetgroup.Group`)


**Manager.Run方法**  

通过`channel tsets`接收到当前最新的拉取对象的信息(`targetgroup.Group`)后：
- `go m.reloader()`  启动协程`reloader`，定期(默认5s)轮询 `m.triggerReload`。如果获取到`reload`信号，执行`Manager.reload()` 方法
- `m.updateTsets(ts)` ： 把接收到的信息(`targetgroup.Group`)暂存在`m.targetSets`字段
- `m.triggerReload <- struct{}{}`: `m.triggerReload`发送`reload`信号
  

代码解析：

```go
// Run receives and saves target set updates and triggers the scraping loops reloading.
// Reloading happens in the background so that it doesn't block receiving targets updates.

func (m *Manager) Run(tsets <-chan map[string][]*targetgroup.Group) error {
	go m.reloader() // 协程启动reloader， 监听更新信息
	// 循环
	for {
		select {
		case ts := <-tsets:   // 在chan tsets 获取到当前最新的拉取对象的信息, chan tsets的send端一般是服务发现组件
			m.updateTsets(ts) // 更新targets,将 m.targetSets 设置为ts

			select {
			case m.triggerReload <- struct{}{}:  // 发生reload信号
			default:
			}

		case <-m.graceShut:  //  关闭信号
			return nil
		}
	}
}


// 将 m.targetSets 设置为ts
func (m *Manager) updateTsets(tsets map[string][]*targetgroup.Group) {
	m.mtxScrape.Lock()
	m.targetSets = tsets
	m.mtxScrape.Unlock()
}

// 监听reload信号 触发更新操作
func (m *Manager) reloader() {
	reloadIntervalDuration := m.opts.DiscoveryReloadInterval
	if reloadIntervalDuration < model.Duration(5*time.Second) {
		reloadIntervalDuration = model.Duration(5 * time.Second)
	}

	ticker := time.NewTicker(time.Duration(reloadIntervalDuration))

	defer ticker.Stop()

	for {
		select {
		case <-m.graceShut:
			return
		case <-ticker.C:  // 定期轮训 m.triggerReload
			select {
			case <-m.triggerReload: // 监听到reload信号，执行reload操作
				m.reload()          // 实际上加载targets的操作
			case <-m.graceShut:
				return
			}
		}
	}
}
``` 

<br/>  

**Manager.reload-热加载的实际执行者**  
执行过程说明：
- 遍历 `m.targetSets ` 为每个 `job`创建 `scrapePool`实例，并将`scrapePool`实例保存在`m.scrapePools`中。`m.targetSets `暂存的是当前最新的抓取目标，是在  `Manager.Run--> Manager.updateTsets(ts) ` 中进行设置的. 
- 协程并发执行`scrapePool.Sync(groups)`,`scrapePools.Sync(groups)`会将`targetGroup`转换为实际的拉取`metrics`的`target`.
- `m.metrics.targetScrapePools.Inc()`:`Manager.metrics` 是对`scrape`模块的监控指标， `Manager.metrics.targetScrapePools`是`Prometheus`的`scrapePool`实例计数，`counter`类型，`metric names`:`prometheus_target_scrape_pools_total`。创建一个新`scrapePool`实例，则`Manager.metrics.targetScrapePools  + 1` ；同理，创建失败则执行`m.metrics.targetScrapePoolsFailed.Inc()`

```go

func (m *Manager) reload() {
	m.mtxScrape.Lock()
	var wg sync.WaitGroup
	// m.targetSets 暂存的是当前最新的抓取目标，是在 Manager.Run--> Manager.updateTsets(ts) 中进行设置的   
	// 遍历m.targetSets为每个job创建 scrapePool
	for setName, groups := range m.targetSets {
		// check 是否存在jop_name的scrapePools，如果不存在，则创建
		if _, ok := m.scrapePools[setName]; !ok {
			// 配置文件中是否存在此job
			scrapeConfig, ok := m.scrapeConfigs[setName]
			if !ok {
				level.Error(m.logger).Log("msg", "error reloading target set", "err", "invalid config id:"+setName)
				continue
			}
			// 为每个targetSet创建scrapePool实例
			m.metrics.targetScrapePools.Inc()  // 创建scrapePool实例,监控指标 +1 
			sp, err := newScrapePool(scrapeConfig, m.append, m.offsetSeed, log.With(m.logger, "scrape_pool", setName), m.buffers, m.opts, m.metrics)
			if err != nil {
				m.metrics.targetScrapePoolsFailed.Inc() // 创建失败,监控指标 +1 
				level.Error(m.logger).Log("msg", "error creating new scrape pool", "err", err, "scrape_pool", setName)
				continue
			}
			m.scrapePools[setName] = sp
		}

		// 启动协程，向scrapePool同步最新的Target Group
		// sp.Sync(groups)  将 Target Group 转换为实际的抓取目标Target，
		// 同步当前运行的 scraper 和结果集，返回全部抓取和丢弃的目标。
		wg.Add(1)
		// Run the sync in parallel as these take a while and at high load can't catch up.
		go func(sp *scrapePool, groups []*targetgroup.Group) {
			sp.Sync(groups)
			wg.Done()
		}(m.scrapePools[setName], groups)

	}
	m.mtxScrape.Unlock()
	wg.Wait()
}
```  
  
<br/>  


## 抓取指标

### scrapePool 结构体

**定义**
```go

// scrapePool manages scrapes for sets of targets.
type scrapePool struct {
	appendable storage.Appendable       // 存储,此接口定义了存储的行为
	logger     log.Logger
	cancel     context.CancelFunc
	httpOpts   []config_util.HTTPClientOption

	// mtx must not be taken after targetMtx.
	mtx    sync.Mutex
	config *config.ScrapeConfig       // 抓取的配置
	client *http.Client               // http client,用于pull指标时 发起http请求
	loops  map[uint64]loop

	targetMtx sync.Mutex
	// activeTargets and loops must always be synchronized to have the same
	// set of hashes.
	activeTargets       map[uint64]*Target  // 抓取的目标endpoint等信息
	droppedTargets      []*Target // Subject to KeepDroppedTargets limit.
	droppedTargetsCount int       // Count of all dropped targets.

	// Constructor for new scrape loops. This is settable for testing convenience.
	newLoop func(scrapeLoopOptions) loop

	noDefaultPort bool

	metrics *scrapeMetrics       // 监控指标
}
```
主要字段说明： 
| 字段名   | 类型  |说明  |备注    |
| :-----| :---- | :---- | :---- |
| `appendable` | `storage.Appendable` | 存储`storage`| `scrapePool`实例`appendable`被赋值为 `fanoutStorage`<br/> 1. `main`调用`scrape.NewManager`创建`scrape.Manager`实例，`scrape.Manager`的`append`字段被赋值`fanoutStorage`<br/> 2. `scrape.reload()`会将`scrape.Manager`的`append`字段传入`newScrapePool`函数，创建`scrapePool`对象。`scrapePool`实例的`appendable`字段就赋值为`fanoutStorage`|
| `config` | `*config.ScrapeConfig` | 抓取的配置 | |
| `activeTargets` | `map[uint64]*Target`  | 需要抓取的target| |
| `droppedTargets`|`int`  | 不需要抓取的target| |
| `droppedTargetsCount`|`[]*Target`  | 不需要抓取的target的数量| |
| `client`|`*http.Client` | `http client`用于`pull`指标时 发起`http`请求|每个`scrapePool`实例只有一个`http client`,向`activeTargets`的多个公用此`http client`|

**思考题**  
1. `activeTargets`、`droppedTargets`都是`Target`集合，为何`activeTargets`以map进行组织，`droppedTargets`选择切片呢？  
todo


